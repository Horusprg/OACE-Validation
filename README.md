# OtimizaÃ§Ã£o de Arquiteturas de Redes Neurais (NAS) para CIFAR-10 com AFSA-GA-PSO e OACE

Este projeto explora uma abordagem inovadora para a OtimizaÃ§Ã£o de Arquiteturas de Redes Neurais (NAS - Neural Architecture Search), utilizando uma combinaÃ§Ã£o de algoritmos de otimizaÃ§Ã£o heurÃ­stica (Artificial Fish Swarm Algorithm - AFSA, Genetic Algorithm - GA e Particle Swarm Optimization - PSO) e um mÃ©todo de avaliaÃ§Ã£o de desempenho multicritÃ©rio chamado Optimized Assertiveness-Cost Evaluation (OACE). O objetivo principal Ã© encontrar arquiteturas de redes neurais otimizadas para o dataset CIFAR-10, que apresentem um equilÃ­brio superior entre alta assertividade (precisÃ£o) e baixo custo computacional.

## ğŸŒŸ VisÃ£o Geral do Projeto

A tarefa de encontrar a arquitetura de rede neural ideal para uma dada aplicaÃ§Ã£o Ã© complexa e exige um balanÃ§o cuidadoso entre desempenho e eficiÃªncia. Modelos de Machine Learning, especialmente os de Deep Learning, frequentemente atingem alta assertividade Ã s custas de um elevado custo computacional, o que pode ser um problema para ambientes com recursos limitados. Este projeto visa superar esse desafio atravÃ©s de uma metodologia de NAS que:

1.  **Otimiza a Estrutura da Rede Neural:** Utiliza uma abordagem hÃ­brida de otimizaÃ§Ã£o meta-heurÃ­stica (AFSA-GA-PSO) para explorar eficientemente o vasto espaÃ§o de busca de arquiteturas.
2.  **Avalia Modelos com OACE:** Emprega o mÃ©todo OACE para avaliar holisticamente as arquiteturas candidatas, combinando mÃ©tricas de assertividade (precisÃ£o, acurÃ¡cia, recall) e custo computacional (parÃ¢metros totais, tempo de inferÃªncia, tamanho do modelo) em um Ãºnico score balanceado.
3.  **Define Pesos de MÃ©tricas com AHP:** Aplica o Analytic Hierarchy Process (AHP) para determinar os pesos ideais das mÃ©tricas de assertividade e custo dentro da funÃ§Ã£o OACE, garantindo uma avaliaÃ§Ã£o objetiva e ponderada.
4.  **Foco no CIFAR-10:** Aplica e valida a metodologia no dataset CIFAR-10, um benchmark popular para classificaÃ§Ã£o de imagens.

## ğŸš€ Metodologia

O projeto segue um pipeline de otimizaÃ§Ã£o de NAS que integra os seguintes componentes:

### 1. RepresentaÃ§Ã£o da Arquitetura Neural

As arquiteturas de redes neurais sÃ£o representadas de forma a permitir a manipulaÃ§Ã£o pelos algoritmos de otimizaÃ§Ã£o. ParÃ¢metros estruturais como o nÃºmero de camadas ocultas e o nÃºmero de neurÃ´nios/filtros por camada sÃ£o codificados como "partÃ­culas" (no contexto do PSO) ou "indivÃ­duos" (no contexto do GA).

### 2. Algoritmo HÃ­brido de OtimizaÃ§Ã£o (AFSA-GA-PSO)

Nosso mÃ©todo de otimizaÃ§Ã£o combina a forÃ§a de trÃªs algoritmos heurÃ­sticos:

* **Particle Swarm Optimization (PSO):** Utilizado como a base do algoritmo de busca, com partÃ­culas explorando o espaÃ§o de soluÃ§Ãµes com base em suas melhores experiÃªncias pessoais (`pbest`) e a melhor experiÃªncia global (`gbest`) do enxame[cite: 325, 329, 330].
* **Artificial Fish Swarm Algorithm (AFSA):** Aplicado para otimizar a inicializaÃ§Ã£o das partÃ­culas do PSO, utilizando comportamentos de aglomeraÃ§Ã£o, forrageamento e busca aleatÃ³ria para encontrar soluÃ§Ãµes iniciais mais promissoras[cite: 217, 345, 361]. Isso ajuda a evitar que o PSO caia em Ã³timos locais prematuramente[cite: 363].
* **Genetic Algorithm (GA):** Introduzido apÃ³s a fase AFSA-PSO para refinar a busca global. Operadores genÃ©ticos como crossover e mutaÃ§Ã£o sÃ£o aplicados para aumentar a diversidade do enxame de partÃ­culas e superar problemas de convergÃªncia prematura do PSO puro[cite: 218, 371]. As probabilidades de crossover e mutaÃ§Ã£o sÃ£o ajustadas dinamicamente durante o processo[cite: 380, 385].

Este algoritmo hÃ­brido busca um equilÃ­brio entre a exploraÃ§Ã£o de novas Ã¡reas do espaÃ§o de busca e a exploraÃ§Ã£o de soluÃ§Ãµes promissoras, visando encontrar a melhor arquitetura de rede neural.

### 3. AvaliaÃ§Ã£o de Desempenho com OACE

O **Optimized Assertiveness-Cost Evaluation (OACE)** Ã© a pedra angular da nossa funÃ§Ã£o de aptidÃ£o. Ele permite uma avaliaÃ§Ã£o holÃ­stica das arquiteturas candidatas, combinando mÃ©tricas de:

* **Assertividade:** PrecisÃ£o, AcurÃ¡cia e Recall, que medem a capacidade do modelo de reconhecer padrÃµes nos dados e minimizar erros de classificaÃ§Ã£o.
* **Custo Computacional:** ParÃ¢metros Totais do Modelo (MTP), Tempo por InferÃªncia (TPI) e Tamanho do Modelo (MS), que avaliam a eficiÃªncia e a leveza do modelo, crucial para ambientes com recursos limitados.

A funÃ§Ã£o OACE agrega essas mÃ©tricas em um Ãºnico score $S_{\phi}$, usando a fÃ³rmula $S_{\phi}(m)=\lambda \cdot A(m) + (1-\lambda) \cdot C(m)$, onde $\lambda$ Ã© um parÃ¢metro de controle que balanceia a importÃ¢ncia entre assertividade ($A(m)$) e custo ($C(m)$). Um $\lambda$ maior que 0.5 Ã© preferÃ­vel para maximizar a assertividade enquanto minimiza o custo.

### 4. Pesos de MÃ©tricas com AHP

Para garantir uma ponderaÃ§Ã£o objetiva das mÃ©tricas de assertividade e custo dentro do OACE, o **Analytic Hierarchy Process (AHP)** Ã© empregado[cite: 87]. O AHP permite a derivaÃ§Ã£o de pesos de prioridade para cada mÃ©trica com base em comparaÃ§Ãµes paritÃ¡rias, transformando um problema complexo em uma hierarquia de critÃ©rios[cite: 88, 90].

### 5. Treinamento e AvaliaÃ§Ã£o das Arquiteturas Candidatas

Cada arquitetura proposta pelo algoritmo de otimizaÃ§Ã£o Ã© treinada no dataset CIFAR-10. Para acelerar o processo de busca, um nÃºmero reduzido de Ã©pocas ou um subconjunto dos dados pode ser utilizado para a avaliaÃ§Ã£o inicial. ApÃ³s o treinamento, as mÃ©tricas de assertividade e custo sÃ£o coletadas, e o score OACE Ã© calculado para determinar a "aptidÃ£o" daquela arquitetura.

## ğŸ“Š Estrutura do Projeto

```
.
â”œâ”€â”€ config.py                   # ConfiguraÃ§Ãµes de parÃ¢metros dos algoritmos e do OACE
â”œâ”€â”€ search.py                   # Script principal para iniciar o NAS
â”œâ”€â”€ train_eval.py               # Script para treinamento e avaliaÃ§Ã£o do melhor modelo encontrado
â”œâ”€â”€ optimize.py                 # OtimizaÃ§Ã£o dos hiperparÃ¢metros do melhor modelo encontrado
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ CapsNet/                # DefiniÃ§Ã£o da estrutura e codificaÃ§Ã£o da arquitetura
â”‚   â”œâ”€â”€ CNN/                    # DefiniÃ§Ã£o da estrutura e codificaÃ§Ã£o da arquitetura
â”‚   â”œâ”€â”€ DBN/                    # DefiniÃ§Ã£o da estrutura e codificaÃ§Ã£o da arquitetura
â”‚   â”œâ”€â”€ DenseNet/               # DefiniÃ§Ã£o da estrutura e codificaÃ§Ã£o da arquitetura
â”‚   â”œâ”€â”€ EfficientNet/           # DefiniÃ§Ã£o da estrutura e codificaÃ§Ã£o da arquitetura
â”‚   â”œâ”€â”€ Inception/              # DefiniÃ§Ã£o da estrutura e codificaÃ§Ã£o da arquitetura
â”‚   â”œâ”€â”€ MLP/                    # DefiniÃ§Ã£o da estrutura e codificaÃ§Ã£o da arquitetura
â”‚   â”œâ”€â”€ MobileNet/              # DefiniÃ§Ã£o da estrutura e codificaÃ§Ã£o da arquitetura
â”‚   â”œâ”€â”€ ResNet/                 # DefiniÃ§Ã£o da estrutura e codificaÃ§Ã£o da arquitetura
â”‚   â”œâ”€â”€ VGG/                    # DefiniÃ§Ã£o da estrutura e codificaÃ§Ã£o da arquitetura
â”‚   â”œâ”€â”€ ViT/                    # DefiniÃ§Ã£o da estrutura e codificaÃ§Ã£o da arquitetura
â”œâ”€â”€ optimizers/
â”‚   â”œâ”€â”€ pso.py                  # ImplementaÃ§Ã£o do Particle Swarm Optimization
â”‚   â”œâ”€â”€ afsa.py                 # ImplementaÃ§Ã£o do Artificial Fish Swarm Algorithm
â”‚   â”œâ”€â”€ ga.py                   # ImplementaÃ§Ã£o do Genetic Algorithm
â”‚   â””â”€â”€ afsa_ga_pso.py          # ImplementaÃ§Ã£o do algoritmo hÃ­brido AFSA-GA-PSO
â”œâ”€â”€ results/                    # Pasta para armazenar os resultados dos experimentos
â”‚   â””â”€â”€ (experimento_X)/        # Subpastas para cada execuÃ§Ã£o
â”‚       â”œâ”€â”€ best_architecture.json
â”‚       â”œâ”€â”€ optimization_log.csv
â”‚       â””â”€â”€ ...
â””â”€â”€ utils/
    â”œâ”€â”€ data_loader.py          # FunÃ§Ãµes para carregar e prÃ©-processar o CIFAR-10
    â”œâ”€â”€ fitness_function.py     # FunÃ§Ã£o de aptidÃ£o (OACE)
    â”œâ”€â”€ ahp_weights.py          # ImplementaÃ§Ã£o do AHP para pesos das mÃ©tricas
    â”œâ”€â”€ evaluate_utils.py       # Pipeline de coleta de mÃ©tricas
    â”œâ”€â”€ training_utils.py       # Pipeline de treinamento
    â”œâ”€â”€ best_model_selection.py # LÃ³gica para seleÃ§Ã£o da melhor arquitetura final
    â”œâ”€â”€ analyze_results.py      # Scripts para visualizaÃ§Ã£o e anÃ¡lise de resultados
    â””â”€â”€ (outros utilitÃ¡rios)
```

## ğŸ› ï¸ Como Executar

1.  **Clone o RepositÃ³rio:**
    ```bash
    git clone https://github.com/seu-usuario/seu-repositorio.git
    cd seu-repositorio
    ```

2.  **Configurar Ambiente (Consulte `requirements.txt`):**
    ```bash
    pip install -r requirements.txt
    ```
    Certifique-se de ter o ambiente CUDA configurado corretamente se for usar GPU.

3.  **Executar a OtimizaÃ§Ã£o NAS:**
    ```bash
    python main.py
    ```
    VocÃª pode ajustar os parÃ¢metros em `config.py` antes de executar.

4.  **Analisar os Resultados:**
    Os resultados dos experimentos serÃ£o salvos na pasta `results/`.
    ```bash
    python utils/analyze_results.py
    ```

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues, enviar pull requests ou sugerir melhorias.

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT.

---