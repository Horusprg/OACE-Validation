"""
Exemplo pr√°tico demonstrando o sistema de logging aprimorado para PSO.
Este script mostra como usar todas as funcionalidades implementadas:
- Logging completo de itera√ß√µes
- Hist√≥rico de pbest/gbest
- Checkpoints autom√°ticos e manuais
- Retomada de otimiza√ß√£o
- An√°lise de resultados
- Exporta√ß√£o de dados
"""

import sys
import os
import numpy as np
from datetime import datetime

# Adiciona o diret√≥rio raiz ao path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from optimizers.pso import PSO
from utils.optimization_utils import OptimizationManager, create_optimization_experiment
from utils.optimization_logger import OptimizationLogger

def demo_basic_logging():
    """
    Demonstra√ß√£o b√°sica do sistema de logging.
    """
    print("=" * 60)
    print("DEMONSTRA√á√ÉO 1: LOGGING B√ÅSICO")
    print("=" * 60)
    
    # 1. Criar gerenciador de otimiza√ß√£o
    manager = OptimizationManager(log_dir="results/demo")
    
    # 2. Configura√ß√£o do experimento
    config = {
        "population_size": 5,
        "max_iter": 10,
        "lambda_param": 0.5,
        "description": "Demonstra√ß√£o b√°sica do sistema de logging",
        "algorithm": "PSO",
        "test_type": "basic_logging"
    }
    
    # 3. Iniciar experimento
    manager.start_experiment(config)
    
    # 4. Criar otimizador PSO
    optimizer = PSO(
        population_size=5,
        n_dim=3,
        max_iter=10,
        lower_bound=-5,
        upper_bound=5
    )
    
    # 5. Fun√ß√£o de fitness para demonstra√ß√£o
    def demo_fitness(x):
        """Fun√ß√£o de fitness simples para demonstra√ß√£o."""
        return -np.sum(x**2, axis=1)  # Maximiza o negativo da soma dos quadrados
    
    # 6. Fun√ß√£o de m√©tricas simulada
    def demo_metrics(x):
        """Simula m√©tricas de uma arquitetura de rede neural."""
        # Simula m√©tricas de assertividade
        assertiveness = np.random.uniform(0.7, 0.95)
        
        # Simula m√©tricas de custo
        total_params = np.random.randint(100000, 1000000)
        inference_time = np.random.uniform(0.01, 0.1)
        memory_used = np.random.uniform(50, 500)
        gflops = np.random.uniform(1, 10)
        
        return {
            "top1_acc": assertiveness,
            "top5_acc": assertiveness + 0.05,
            "precision_macro": assertiveness - 0.02,
            "recall_macro": assertiveness - 0.01,
            "f1_macro": assertiveness - 0.015,
            "total_params": total_params,
            "avg_inference_time": inference_time,
            "memory_used_mb": memory_used,
            "gflops": gflops
        }
    
    # 7. Executar otimiza√ß√£o
    print("\nüîÑ Executando otimiza√ß√£o...")
    best_position, best_fitness = manager.run_optimization(
        optimizer=optimizer,
        fitness_function=demo_fitness,
        metrics_function=demo_metrics
    )
    
    # 8. Analisar resultados
    print("\nüìä Analisando resultados...")
    summary = manager.get_experiment_summary()
    print(f"   ‚Ä¢ ID do experimento: {summary['experiment_id']}")
    print(f"   ‚Ä¢ Progresso: {summary['progress']}")
    print(f"   ‚Ä¢ Melhor solu√ß√£o: {summary['best_solution']}")
    print(f"   ‚Ä¢ Arquivos dispon√≠veis: {summary['files_available']}")
    
    # 9. Exportar dados
    print("\nüìÅ Exportando dados...")
    manager.export_experiment_data(format="all")
    
    return manager.current_experiment

def demo_checkpoint_resume():
    """
    Demonstra√ß√£o de checkpoint e retomada de otimiza√ß√£o.
    """
    print("\n" + "=" * 60)
    print("DEMONSTRA√á√ÉO 2: CHECKPOINT E RETOMADA")
    print("=" * 60)
    
    # 1. Criar gerenciador
    manager = OptimizationManager(log_dir="results/demo")
    
    # 2. Configura√ß√£o
    config = {
        "population_size": 3,
        "max_iter": 15,
        "lambda_param": 0.5,
        "description": "Demonstra√ß√£o de checkpoint e retomada",
        "algorithm": "PSO",
        "test_type": "checkpoint_resume"
    }
    
    # 3. Iniciar experimento
    manager.start_experiment(config)
    
    # 4. Criar otimizador
    optimizer = PSO(
        population_size=3,
        n_dim=2,
        max_iter=15,
        lower_bound=-3,
        upper_bound=3
    )
    
    # 5. Fun√ß√£o de fitness
    def demo_fitness(x):
        return -np.sum(x**2, axis=1)
    
    # 6. Fun√ß√£o de m√©tricas
    def demo_metrics(x):
        return {
            "top1_acc": np.random.uniform(0.8, 0.95),
            "total_params": np.random.randint(50000, 500000),
            "avg_inference_time": np.random.uniform(0.005, 0.05),
            "memory_used_mb": np.random.uniform(25, 250),
            "gflops": np.random.uniform(0.5, 5)
        }
    
    # 7. Executar otimiza√ß√£o (ser√° interrompida)
    print("\nüîÑ Executando otimiza√ß√£o (ser√° interrompida)...")
    
    # Simula interrup√ß√£o ap√≥s algumas itera√ß√µes
    try:
        best_position, best_fitness = manager.run_optimization(
            optimizer=optimizer,
            fitness_function=demo_fitness,
            metrics_function=demo_metrics
        )
    except KeyboardInterrupt:
        print("\n‚è∏Ô∏è Otimiza√ß√£o interrompida pelo usu√°rio")
        
        # Salva checkpoint manual
        manager.pause_optimization("Interrup√ß√£o manual para demonstra√ß√£o")
        
        # Simula retomada
        print("\nüîÑ Retomando otimiza√ß√£o...")
        
        # Cria novo otimizador
        optimizer2 = PSO(
            population_size=3,
            n_dim=2,
            max_iter=15,
            lower_bound=-3,
            upper_bound=3
        )
        
        # Encontra o √∫ltimo checkpoint
        experiment_dir = os.path.join("results/demo", manager.current_experiment)
        checkpoint_files = [f for f in os.listdir(experiment_dir) if f.startswith("checkpoint")]
        
        if checkpoint_files:
            latest_checkpoint = sorted(checkpoint_files)[-1]
            checkpoint_path = os.path.join(experiment_dir, latest_checkpoint)
            
            # Retoma a otimiza√ß√£o
            best_position, best_fitness = manager.resume_from_checkpoint(
                checkpoint_file=checkpoint_path,
                optimizer=optimizer2,
                fitness_function=demo_fitness,
                metrics_function=demo_metrics
            )
            
            print(f"‚úÖ Otimiza√ß√£o retomada e conclu√≠da!")
            print(f"   ‚Ä¢ Melhor posi√ß√£o: {best_position}")
            print(f"   ‚Ä¢ Melhor fitness: {best_fitness}")
    
    return manager.current_experiment

def demo_analysis_and_export():
    """
    Demonstra√ß√£o de an√°lise e exporta√ß√£o de resultados.
    """
    print("\n" + "=" * 60)
    print("DEMONSTRA√á√ÉO 3: AN√ÅLISE E EXPORTA√á√ÉO")
    print("=" * 60)
    
    # 1. Criar gerenciador
    manager = OptimizationManager(log_dir="results/demo")
    
    # 2. Listar experimentos existentes
    print("\nüìã Experimentos dispon√≠veis:")
    experiments = manager.list_experiments()
    for exp in experiments:
        print(f"   ‚Ä¢ {exp['id']}: {exp['status']} (score: {exp['best_score']:.4f})")
    
    # 3. Analisar um experimento espec√≠fico (se existir)
    if experiments:
        experiment_id = experiments[0]['id']
        print(f"\nüìä Analisando experimento: {experiment_id}")
        
        analysis = manager.analyze_results(experiment_id)
        print(f"   ‚Ä¢ Total de itera√ß√µes: {analysis['total_iterations']}")
        print(f"   ‚Ä¢ Total de avalia√ß√µes: {analysis['total_evaluations']}")
        print(f"   ‚Ä¢ Melhor score: {analysis['best_score']:.4f}")
        print(f"   ‚Ä¢ Fases executadas: {analysis['phases_executed']}")
        print(f"   ‚Ä¢ Checkpoints criados: {analysis['checkpoints_created']}")
        
        if 'fitness_progression' in analysis:
            prog = analysis['fitness_progression']
            print(f"   ‚Ä¢ Progress√£o do fitness:")
            print(f"     - Inicial: {prog['initial_fitness']:.4f}")
            print(f"     - Final: {prog['final_fitness']:.4f}")
            print(f"     - Melhoria: {prog['improvement']:.4f}")
            print(f"     - M√°ximo: {prog['max_fitness']:.4f}")
            print(f"     - M√≠nimo: {prog['min_fitness']:.4f}")
        
        # 4. Exportar dados
        print(f"\nüìÅ Exportando dados do experimento...")
        manager.export_experiment_data(experiment_id, format="all")
        
        # 5. Carregar dados brutos
        print(f"\nüìÑ Carregando dados brutos...")
        raw_data = manager.logger.load_checkpoint(
            os.path.join("results/demo", experiment_id, "optimization_log.json")
        )
        print(f"   ‚Ä¢ Dados carregados com sucesso")
        print(f"   ‚Ä¢ Estrutura: {list(raw_data.keys())}")

def demo_advanced_logging():
    """
    Demonstra√ß√£o de logging avan√ßado com m√∫ltiplas fases.
    """
    print("\n" + "=" * 60)
    print("DEMONSTRA√á√ÉO 4: LOGGING AVAN√áADO")
    print("=" * 60)
    
    # 1. Criar logger diretamente
    logger = OptimizationLogger(log_dir="results/demo")
    
    # 2. Configura√ß√£o
    config = {
        "population_size": 4,
        "max_iter": 8,
        "lambda_param": 0.5,
        "description": "Demonstra√ß√£o de logging avan√ßado",
        "algorithm": "PSO",
        "test_type": "advanced_logging"
    }
    
    # 3. Iniciar experimento
    logger.start_experiment(config)
    
    # 4. Simular m√∫ltiplas fases de otimiza√ß√£o
    phases = ["AFSA", "PSO", "GA"]
    
    for phase_idx, phase in enumerate(phases):
        print(f"\nüîÑ Executando fase: {phase}")
        
        for iteration in range(1, 4):  # 3 itera√ß√µes por fase
            # Simula popula√ß√£o
            population = np.random.rand(4, 3)
            fitness_values = np.random.rand(4)
            best_position = population[np.argmax(fitness_values)]
            best_fitness = np.max(fitness_values)
            
            # Simula pbest/gbest
            pbest_pos = population.copy()
            pbest_cost = fitness_values.copy()
            gbest_pos = best_position.copy()
            gbest_cost = best_fitness
            
            # Simula m√©tricas
            metrics = {
                "top1_acc": np.random.uniform(0.8, 0.95),
                "top5_acc": np.random.uniform(0.85, 0.98),
                "precision_macro": np.random.uniform(0.75, 0.9),
                "recall_macro": np.random.uniform(0.75, 0.9),
                "f1_macro": np.random.uniform(0.75, 0.9),
                "total_params": np.random.randint(100000, 1000000),
                "avg_inference_time": np.random.uniform(0.01, 0.1),
                "memory_used_mb": np.random.uniform(50, 500),
                "gflops": np.random.uniform(1, 10)
            }
            
            # Simula configura√ß√£o de arquitetura
            architecture_config = {
                "model_type": f"TestModel_{phase}",
                "layers": np.random.randint(3, 8),
                "neurons": np.random.randint(64, 512),
                "dropout": np.random.uniform(0.1, 0.5)
            }
            
            # Log da itera√ß√£o
            logger.log_iteration(
                iteration=iteration + phase_idx * 3,
                phase=phase,
                population=population,
                fitness_values=fitness_values,
                best_position=best_position,
                best_fitness=best_fitness,
                metrics=metrics,
                pbest_pos=pbest_pos,
                pbest_cost=pbest_cost,
                gbest_pos=gbest_pos,
                gbest_cost=gbest_cost,
                architecture_config=architecture_config
            )
            
            # Checkpoint a cada 3 itera√ß√µes
            if iteration % 3 == 0:
                logger.log_checkpoint(
                    iteration=iteration + phase_idx * 3,
                    phase=phase,
                    population=population,
                    fitness_values=fitness_values,
                    best_position=best_position,
                    best_fitness=best_fitness
                )
    
    # 5. Finalizar experimento
    logger.log_final_results(
        best_architecture="TestModel_PSO",
        best_params={"layers": 5, "neurons": 256, "dropout": 0.3},
        best_fitness=0.92,
        final_metrics={"top1_acc": 0.92, "total_params": 500000}
    )
    
    print(f"\n‚úÖ Logging avan√ßado conclu√≠do!")
    print(f"   ‚Ä¢ Experimento: {logger.current_experiment}")
    print(f"   ‚Ä¢ Total de itera√ß√µes: {len(logger.log_data['iterations'])}")
    print(f"   ‚Ä¢ Fases executadas: {list(set([it['phase'] for it in logger.log_data['iterations']]))}")

def main():
    """
    Fun√ß√£o principal que executa todas as demonstra√ß√µes.
    """
    print("üöÄ INICIANDO DEMONSTRA√á√ïES DO SISTEMA DE LOGGING APRIMORADO")
    print("=" * 80)
    
    try:
        # Demonstra√ß√£o 1: Logging b√°sico
        exp1 = demo_basic_logging()
        
        # Demonstra√ß√£o 2: Checkpoint e retomada
        exp2 = demo_checkpoint_resume()
        
        # Demonstra√ß√£o 3: An√°lise e exporta√ß√£o
        demo_analysis_and_export()
        
        # Demonstra√ß√£o 4: Logging avan√ßado
        demo_advanced_logging()
        
        print("\n" + "=" * 80)
        print("‚úÖ TODAS AS DEMONSTRA√á√ïES CONCLU√çDAS COM SUCESSO!")
        print("=" * 80)
        print("\nüìÅ Arquivos gerados:")
        print("   ‚Ä¢ results/demo/ - Diret√≥rio com todos os experimentos")
        print("   ‚Ä¢ optimization_log.json - Log completo de cada experimento")
        print("   ‚Ä¢ avaliacoes_arquiteturas.csv - Resumo em CSV")
        print("   ‚Ä¢ pbest_history.csv - Hist√≥rico de pbest")
        print("   ‚Ä¢ gbest_history.csv - Hist√≥rico de gbest")
        print("   ‚Ä¢ detailed_metrics.csv - M√©tricas detalhadas")
        print("   ‚Ä¢ optimization_summary.json - Resumo da otimiza√ß√£o")
        print("   ‚Ä¢ checkpoint_*.json - Checkpoints autom√°ticos e manuais")
        
        print("\nüîß Funcionalidades demonstradas:")
        print("   ‚úÖ Logging completo de itera√ß√µes")
        print("   ‚úÖ Hist√≥rico de pbest e gbest")
        print("   ‚úÖ Checkpoints autom√°ticos e manuais")
        print("   ‚úÖ Retomada de otimiza√ß√£o")
        print("   ‚úÖ An√°lise de resultados")
        print("   ‚úÖ Exporta√ß√£o em m√∫ltiplos formatos")
        print("   ‚úÖ Gerenciamento de experimentos")
        
    except Exception as e:
        print(f"\n‚ùå Erro durante as demonstra√ß√µes: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 